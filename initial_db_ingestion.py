import pandas as pd
import os
import re
from sqlalchemy import create_engine, text, types
from pathlib import Path
from dotenv import load_dotenv

# 1. í™˜ê²½ ì„¤ì • ë° DB ì—°ê²°
PROJECT_ROOT = Path(__file__).parent
load_dotenv(PROJECT_ROOT / ".env")

DB_URL = os.getenv("LOCAL_DB_URL") 
engine = create_engine(DB_URL)

# --- [ì •ì œ ë¡œì§] ---
def clean_spec(text_val):
    if pd.isna(text_val): return None
    match = re.search(r'(\d+\.?\d*)', str(text_val))
    return match.group(1) if match else None

# --- [ìˆ˜ë™ ìœ„ê²½ë„ ë°ì´í„°] ---
MANUAL_PLANT_DATA = [
    {'gcd': '997D', 'hg': '1', 'lat': 33.2373862, 'lon': 126.3418842}, # ë‚¨ì œì£¼
    {'gcd': '997G', 'hg': '1', 'lat': 35.0586428, 'lon': 128.8157557}, # ë¶€ì‚°ì‹ í•­
    {'gcd': '997N', 'hg': '1', 'lat': 35.0586428, 'lon': 128.8157557}, # ë¶€ì‚°ë³µí•©ìì¬
    {'gcd': 'B997', 'hg': '1', 'lat': 35.0870019, 'lon': 128.9989357}, # ë¶€ì‚°ë³¸ë¶€ 1
    {'gcd': 'B997', 'hg': '2', 'lat': 35.0870019, 'lon': 128.9989357}, # ë¶€ì‚°ë³¸ë¶€ 2
    {'gcd': '997Q', 'hg': '1', 'lat': 35.2591938, 'lon': 129.2235041}, # ë¶€ì‚°ìˆ˜ì²˜ë¦¬ì¥
    {'gcd': '997R', 'hg': '1', 'lat': 35.1902253, 'lon': 129.0563480}, # ë¶€ì‚°ìš´ë™ì¥
    {'gcd': '9987', 'hg': '1', 'lat': 35.1157106, 'lon': 129.0428212}, # ë¶€ì‚°ì—­ì„ ìƒ
    {'gcd': '997S', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318, 'cap': '1742', 'ang': '20', 'mod': '475W x 3,668', 'inv': '250kW x 7EA'},
    {'gcd': '997Y', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318, 'cap': '907.2', 'ang': '23', 'mod': '360W x 2,520', 'inv': '250kW x 4EA'},
    {'gcd': '8760', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318}, # ì‹ ì¸ì²œì†Œë‚´
    {'gcd': '9985', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318}, # ì‹ ì¸ì²œì£¼ì°¨ì¥
    {'gcd': '9988', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318}, # ì‹ ì¸ì²œë¶ì¸¡
    {'gcd': '9989', 'hg': '1', 'lat': 37.536111, 'lon': 126.602318}, # ì‹ ì¸ì²œ 1,2ë‹¨ê³„
    {'gcd': '9979', 'hg': '1', 'lat': 37.3335822, 'lon': 127.4795795}, # ì´ì²œD
    {'gcd': 'S997', 'hg': '1', 'lat': 37.1902416, 'lon': 129.3387384, 'cap': '999', 'ang': '25', 'mod': '360W x 2,775', 'inv': '500kW x 2EA'},
    {'gcd': 'S997', 'hg': '2', 'lat': 37.1902416, 'lon': 129.3387384, 'cap': '990.45', 'ang': '25', 'mod': '355W x 2,790', 'inv': '500kW x 2EA'},
    {'gcd': 'S997', 'hg': '3', 'lat': 37.1902416, 'lon': 129.3387384, 'cap': '2002.32', 'ang': '25', 'mod': '360W x 5,562', 'inv': '500kW x 1EA, 1500kW x 1EA'}
]

def run_ingestion():
    PROCESSED_DIR = PROJECT_ROOT / "pv_data_processed"
    files = sorted(list(PROCESSED_DIR.glob("nambu_processed_*.csv")))
    
    if not files:
        print("âŒ ê°€ê³µëœ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- 1ë‹¨ê³„: í…Œì´ë¸” ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ì„¤ì • (renit_db.py ìŠ¤íƒ€ì¼) ---
    print("ğŸ§¹ 1. í…Œì´ë¸” ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ì„¤ì • ì¤‘...")
    with engine.begin() as conn:
        # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
        conn.execute(text("DROP TABLE IF EXISTS pv_generation CASCADE;"))
        conn.execute(text("DROP TABLE IF EXISTS plant_info CASCADE;"))
        
        # pv_generation í…Œì´ë¸” ìƒì„± (Primary Key ì¶”ê°€ë¡œ ë°ì´í„° ì¤‘ë³µ ë°©ì§€)
        conn.execute(text("""
            CREATE TABLE pv_generation (
                timestamp TIMESTAMP NOT NULL,
                ipptnm TEXT NOT NULL,
                hogi TEXT NOT NULL,
                generation FLOAT,
                gencd TEXT,
                PRIMARY KEY (timestamp, ipptnm, hogi) -- ì¤‘ë³µ ë°ì´í„° ë°©ì§€ í•µì‹¬!
            );
        """))
    print("âœ… í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")

    # --- 2ë‹¨ê³„: ë§ˆìŠ¤í„° í…Œì´ë¸”(plant_info) ìƒì„± ---
    print("ğŸ  2. ë§ˆìŠ¤í„° í…Œì´ë¸”(plant_info) êµ¬ì¶• ì¤‘...")
    sample_dfs = []
    for f in files:
        df_tmp = pd.read_csv(f, encoding='utf-8-sig').iloc[:1]
        sample_dfs.append(df_tmp)
    
    df_master = pd.concat(sample_dfs).drop_duplicates(['gencd', 'hogi'])
    df_master['capacity_kw'] = df_master['ì„¤ì¹˜ìš©ëŸ‰'].apply(clean_spec)
    df_master['angle_deg'] = df_master['ì„¤ì¹˜ê°'].apply(clean_spec)
    
    df_manual = pd.DataFrame(MANUAL_PLANT_DATA)
    df_master = pd.merge(df_master, df_manual, left_on=['gencd', 'hogi'], right_on=['gcd', 'hg'], how='left')
    
    master_cols = {
        'gencd': 'gencd', 'hogi': 'hogi', 'ipptnm': 'plant_name', 
        'ë°œì „ì†Œ ì£¼ì†Œì§€': 'address', 'capacity_kw': 'capacity_kw', 
        'angle_deg': 'angle_deg', 'lat': 'lat', 'lon': 'lon',
        'mod': 'module_spec', 'inv': 'inverter_spec'
    }
    df_master_final = df_master[list(master_cols.keys())].rename(columns=master_cols)
    df_master_final.to_sql('plant_info', con=engine, if_exists='replace', index=False)

    # --- 3ë‹¨ê³„: ì‹œê³„ì—´ ë°ì´í„°(pv_generation) ì ì¬ ë° ì¤‘ë³µ ì œê±° ---
    print(f"ğŸ“ˆ 3. ì‹œê³„ì—´ ë°ì´í„° ì ì¬ ì‹œì‘ ({len(files)}ê°œ íŒŒì¼)...")
    for file_path in files:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['generation'] = pd.to_numeric(df['generation'], errors='coerce').fillna(0)
        
        # [ì¤‘ìš”!] CSV ë‚´ë¶€ì˜ ì¤‘ë³µ ë°ì´í„° ì œê±° (renit_db ë¡œì§)
        df = df.drop_duplicates(subset=['timestamp', 'ipptnm', 'hogi'], keep='first')
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ì ì¬
        df_gen = df[['timestamp', 'ipptnm', 'hogi', 'generation', 'gencd']]
        df_gen.to_sql('pv_generation', con=engine, if_exists='append', index=False)
        print(f"  - âœ… {file_path.name} ì´ê´€ ì™„ë£Œ ({len(df_gen)}í–‰)")

    print("\nğŸ‰ ëª¨ë“  ë°ì´í„°ê°€ ì¤‘ë³µ ì—†ì´ ê¹¨ë—í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    run_ingestion()