import asyncio
import aiohttp
import pandas as pd
import xml.etree.ElementTree as ET
import os
from pathlib import Path
from datetime import datetime, timedelta
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from prefect import flow, task
import os
from dotenv import load_dotenv

load_dotenv()

# 1. í™˜ê²½ ë° DB ì„¤ì •
current_file = Path(__file__).resolve()
PROJECT_ROOT = current_file.parent.parent.parent # í´ë” êµ¬ì¡°ì— ë§ì¶° ìƒìœ„ í´ë” ì§€ì •
load_dotenv(PROJECT_ROOT / ".env")

API_KEY = os.getenv("NAMBU_API_KEY")
ENDPOINT = "https://apis.data.go.kr/B552520/PwrSunLightInfo/getDataService"
DB_URL = os.getenv("DB_URL")

engine = create_engine(DB_URL)

# --- [Task 1: ìˆ˜ì§‘ ëŒ€ìƒ ë° ì‹œì‘ ì‹œì  ë¶„ì„] ---
@task(name="Get Active Collection Targets", log_prints=True)
def get_active_targets():
    """
    plant_info í…Œì´ë¸”ì„ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì§‘ ëŒ€ìƒì„ ì •í•˜ê³ ,
    pv_generationì˜ ë§ˆì§€ë§‰ ê¸°ë¡ì„ í™•ì¸í•˜ì—¬ ê°€ë™ ì¤‘ë‹¨ ì—¬ë¶€ì™€ ì‹œì‘ì¼ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    query = """
    SELECT 
        p.gencd, 
        p.hogi, 
        p.ipptnm, 
        MAX(g.timestamp) as last_date
    FROM plant_info p
    LEFT JOIN pv_generation g ON p.ipptnm = g.ipptnm AND p.hogi = g.hogi
    GROUP BY p.gencd, p.hogi, p.ipptnm
    """
    with engine.connect() as conn:
        df = pd.read_sql(text(query), conn)
    
    active_targets = []
    yesterday = datetime.now() - timedelta(days=1)

    for _, row in df.iterrows():
        last_date = row['last_date']
        
        # í•„í„°ë§: ë§ˆì§€ë§‰ ê¸°ë¡ì´ 2025ë…„ ì´ì „ì´ë©´ ë°œì „ ì¤‘ë‹¨ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ìŠ¤í‚µ
        if last_date and last_date.year < 2025:
            print(f"â© {row['ipptnm']} ({row['hogi']}í˜¸ê¸°): {last_date.year}ë…„ ì´í›„ ê¸°ë¡ ì—†ìŒ. ìˆ˜ì§‘ ì œì™¸.")
            continue
            
        # ì‹œì‘ ë‚ ì§œ ê²°ì • (ë§ˆì§€ë§‰ ê¸°ë¡ ë‹¤ìŒë‚  í˜¹ì€ ë°ì´í„° ì—†ìœ¼ë©´ 1ë…„ ì „)
        start_dt = (last_date + timedelta(days=1)) if last_date else (datetime.now() - timedelta(days=365))
        
        if start_dt.date() <= yesterday.date():
            active_targets.append({
                'gencd': str(row['gencd']),
                'hogi': str(row['hogi']),
                'ipptnm': row['ipptnm'],
                'start_dt': start_dt
            })
            
    print(f"âœ… ì´ {len(active_targets)}ê°œ ë°œì „ì†Œê°€ í™œì„± ìƒíƒœì´ë©° ìˆ˜ì§‘ ëŒ€ìƒì…ë‹ˆë‹¤.")
    return active_targets

# --- [Task 2: API ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬] ---
async def fetch_api_data(session, date_str, gencd, hogi):
    """API í˜¸ì¶œ (strHoki íŒŒë¼ë¯¸í„° ì‚¬ìš©)"""
    params = {
        "serviceKey": API_KEY, "pageNo": "1", "numOfRows": "100",
        "strSdate": date_str, "strEdate": date_str,
        "strOrgCd": gencd, "strHoki": hogi
    }
    try:
        async with session.get(ENDPOINT, params=params, timeout=15) as response:
            if response.status != 200: return None
            root = ET.fromstring(await response.text())
            items = root.find('.//items')
            return {child.tag: child.text for child in items} if items is not None else None
    except:
        return None

@task(name="Collect and Save Solar Data", log_prints=True)
async def collect_and_save(targets):
    """í™œì„± ë°œì „ì†Œë“¤ì— ëŒ€í•´ API ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ DBì— ì €ì¥"""
    yesterday = datetime.now() - timedelta(days=1)
    total_rows = 0

    async with aiohttp.ClientSession() as session:
        for target in targets:
            date_list = pd.date_range(start=target['start_dt'], end=yesterday).strftime("%Y%m%d").tolist()
            if not date_list: continue

            print(f"ğŸ“¡ {target['ipptnm']} ({target['hogi']}í˜¸ê¸°) {len(date_list)}ì¼ë¶„ ìˆ˜ì§‘ ì¤‘...")
            
            raw_data = []
            for d_str in date_list:
                data = await fetch_api_data(session, d_str, target['gencd'], target['hogi'])
                if data:
                    data['gencd'], data['hogi'] = target['gencd'], target['hogi']
                    raw_data.append(data)
                await asyncio.sleep(0.05)

            if raw_data:
                # ì „ì²˜ë¦¬: 24ì‹œê°„ ë°ì´í„°ë¥¼ ì„¸ë¡œë¡œ ë³€í™˜
                df_raw = pd.DataFrame(raw_data)
                v_vars = [c for c in df_raw.columns if c.startswith('qhorgen')]
                df_long = df_raw.melt(id_vars=['ymd', 'hogi', 'gencd'], value_vars=v_vars, 
                                      var_name='h_str', value_name='generation')
                
                df_long['hour'] = df_long['h_str'].str.extract(r'(\d+)').astype(int)
                df_long['timestamp'] = pd.to_datetime(df_long['ymd']) + pd.to_timedelta(df_long['hour'], unit='h')
                df_long['generation'] = pd.to_numeric(df_long['generation'], errors='coerce').fillna(0)
                df_long['ipptnm'] = target['ipptnm'] # ë§ˆìŠ¤í„° í…Œì´ë¸” ëª…ì¹­ ê°•ì œ ì ìš©

                final_df = df_long[['timestamp', 'ipptnm', 'hogi', 'generation', 'gencd']]
                
                with engine.begin() as conn:
                    final_df.to_sql('pv_generation', con=conn, if_exists='append', index=False)
                
                total_rows += len(final_df)
                print(f"   ã„´ âœ… {len(final_df)}í–‰ ì €ì¥ ì™„ë£Œ")

    return total_rows

# --- [Flow: ì „ì²´ ì›Œí¬í”Œë¡œìš° ì œì–´] ---
@flow(name="Daily Nambu Solar Collection Flow", log_prints=True)
def solar_automation_flow():
    # 1. ìˆ˜ì§‘ ëŒ€ìƒ ë¶„ì„
    targets = get_active_targets()
    
    # 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
    if targets:
        asyncio.run(collect_and_save(targets))
    else:
        print("â˜€ï¸ ëª¨ë“  ë°œì „ì†Œê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    solar_automation_flow()

    #teset